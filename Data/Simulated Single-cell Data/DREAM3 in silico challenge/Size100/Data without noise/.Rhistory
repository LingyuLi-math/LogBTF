694*0.04
694*0.041
694*0.042
694*0.044
library(ggplot2)
library(ggpubr)
library(Rcpp)
pred_log = read.table("D:\\E\\博士\\R_程序\\HGSOC\\DataPRS\\pre59491_73685_4cvlog.txt", header = T, check.names = FALSE)
dim(pred_log)
term0 <- which(pred_log$Lable == 0)
pred_log[term0, 2] <- "Term"
term1 <- which(pred_log$Lable == 1)
pred_log[term1, 2] <- "SPTB"
# treatment <- c(2745.6, 1697.1, 1656.4, 978, 703.4, 489.1, 430, 334.1, 302.8, 274.7, 274.7, 255, 242.5, 200.7, 198.6, 129.6, 119, 118.3, 115.3, 92.4, 40.6, 32.7, 31.4, 17.5, 7.7, 4.1)
# control <- c(1202.6, 830.1, 372.4, 345.5, 321.2, 244.3, 163, 147.8, 95, 87, 81.2, 68.5, 47.3, 41.1, 36.6, 29, 28.6, 26.3, 26, 24.4, 21.4, 17.3, 11.5, 4.9, 4.9, 1.0)
# data <- rbind(as.matrix(treatment), as.matrix(control))
# label <- c(rep("Treatment", 26), rep("Control", 26))
# pred_log <- as.data.frame(cbind(data, label))
# # colnames(data_1) <- c("Value", "Label")
colnames(pred_log) <- c("preterm_risk_score","label")
# View(pred_log)
head(pred_log)
class(pred_log)
###########################################   画图   ##############################################
pred_log$lable <- as.factor(pred_log$label)  # dose 为列名，即表达值
e <- ggplot(pred_log, aes(x = label, y = preterm_risk_score))  # x 有三类，就有3个箱子
# Basic box plot
e + geom_boxplot()
e + geom_boxplot(aes(fill = label), position=position_dodge(0.8)) +
geom_jitter(aes(color = label, shape = label),
position=position_dodge(0.8))
# example -----------------------------------------------------------------
# data("ToothGrowth")
# head(ToothGrowth)
# p <- ggboxplot(ToothGrowth, x = "supp", y = "len",
#                color = "supp", palette = "npg", add = "jitter")
# my_comparisons <- list( c("0.5", "1"), c("1", "2"), c("0.5", "2") )
# ggboxplot(ToothGrowth, x = "dose", y = "len",
#           color = "dose", palette = "jco")+
#   stat_compare_means(comparisons = my_comparisons) + # Add pairwise comparisons p-value
#   # stat_compare_means(label.y = 50)     # Add global p-value
#   stat_compare_means(method = "t.test", label.y = 50)
# test --------------------------------------------------------------------
ee <- ggboxplot(pred_log, x = "label", y = "preterm_risk_score", color = "label",
palette = "npg", add = "jitter")
my_comparisons <- list( c("SPTB", "Term") )
# my_comparisons <- list( c("Treatment", "Control") )
ee + stat_compare_means(comparisons = my_comparisons)
# my_comparisons <- list( c("Treatment", "Control") )
ee + stat_compare_means(comparisons = my_comparisons,method = "wilcox.test")
# my_comparisons <- list( c("Treatment", "Control") )
ee + stat_compare_means(comparisons = my_comparisons,method = "wilcox.test")
# my_comparisons <- list( c("Treatment", "Control") )
ee + stat_compare_means(comparisons = my_comparisons,method = "t.test")   wilcox.test
# my_comparisons <- list( c("Treatment", "Control") )
ee + stat_compare_means(comparisons = my_comparisons,method = "t.test")  # wilcox.test
# my_comparisons <- list( c("Treatment", "Control") )
ee + stat_compare_means(comparisons = my_comparisons,method = "wilcox.test")  # t.test
14+24+38+195
rm(list = ls())
##
install.packages("gglasso")
install.packages("ExclusiveLasso")
library(gglasso)
library(ExclusiveLasso)
library(devtools)
install_github("DataSlingers/ExclusiveLasso")
library(gglasso)
library(ExclusiveLasso)
library(glmnet)
library(gglasso)
library(ExclusiveLasso)
graphics.off()  # clear all graphs
rm(list = ls()) # remove all files from your workspace
set.seed(1234)
N = 500 # number of observations
p = 20  # number of variables
# random generated X
X = matrix(rnorm(N*p), ncol=p)
# standardization : mean = 0, std=1
X = scale(X)
# artificial coefficients
beta = c(0.15,–0.33,0.25,–0.25,0.05,0,0,0,0.5,0.2,–0.25, 0.12,–0.125,0,0,0,0,0,0,0)
# artificial coefficients
beta = c(0.15,-0.33,0.25,-0.25,0.05,0,0,0,0.5,0.2,-0.25, 0.12,-0.125,0,0,0,0,0,0,0)
# Y variable, standardized Y
y = X%*%beta + rnorm(N, sd=0.5)
# group index for X variables
v.group <- c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4)
# lasso
la <- glmnet(X, y, lambda = 0.1,
family="gaussian", alpha=1,
intercept = F)
# group lasso
gr <- gglasso(X, y, lambda = 0.2,
group = v.group, loss="ls",
intercept = F)
# exclusive lasso
ex <- exclusive_lasso(X, y,lambda = 0.2,
groups = v.group, family="gaussian",
intercept = F)
# Results
df.comp <- data.frame(
group = v.group, beta = beta,
Lasso     = la$beta[,1],
Group     = gr$beta[,1],
Exclusive = ex$coef[,1]
)
df.comp
# lasso
la_cv <- cv.glmnet(x=X, y=y, family='gaussian',
alpha=1, intercept = F, nfolds=5)
x11(); plot(la_cv)
paste(la_cv$lambda.min, la_cv$lambda.1se)
# group lasso
gr_cv <- cv.gglasso(x=X, y=y, group=v.group,
loss="ls", pred.loss="L2",
intercept = F, nfolds=5)
x11(); plot(gr_cv)
plot(gr_cv)
plot(la_cv)
plot(gr_cv)
# exclusive lasso
ex_cv <- cv.exclusive_lasso(
X, y, groups = v.group,
intercept = F, nfolds=5)
plot(ex_cv)
# lasso
la <- glmnet(X, y, lambda = la_cv$lambda.1se,
family="gaussian", alpha=1,
intercept = F)
# group lasso
gr <- gglasso(X, y, lambda = gr_cv$lambda.1se+0.1,
group = v.group, loss="ls",
intercept = F)
# exclusive lasso
ex <- exclusive_lasso(X, y,lambda = ex_cv$lambda.1se,
groups = v.group, family="gaussian",
intercept = F)
# Results
df.comp.lambda.1se <- data.frame(
group = v.group, beta = beta,
Lasso     = la$beta[,1],
Group     = gr$beta[,1],
Exclusive = ex$coef[,1]
)
df.comp.lambda.1se
if(!require('kernlab')) {
# install.packages('kernlab')
library('kernlab')
}
## simple example using the spam data set
data(spam)
rm(list = ls())
if(!require('kernlab')) {
# install.packages('kernlab')
library('kernlab')
}
## simple example using the spam data set
data(spam)
## create test and training set
index <- sample(1:dim(spam)[1])
spamtrain <- spam[index[1:floor(dim(spam)[1]/2)], ]
spamtest <- spam[index[((ceiling(dim(spam)[1]/2)) + 1):dim(spam)[1]], ]
## train a support vector machine
filter <- ksvm(type~.,data=spamtrain,kernel="rbfdot",
kpar=list(sigma=0.05),C=5,cross=3)
View(spamtrain[,1:10])
filter
## predict mail type on the test set
mailtype <- predict(filter,spamtest[,-58])
## Check results
table(mailtype,spamtest[,58])
## train a support vector machine
filter <- ksvm(type~.,data=spamtrain,kernel="rbfdot",
kpar=list(sigma=0.05),C=5,cross=3)
filter
## predict mail type on the test set
mailtype <- predict(filter,spamtest[,-58])
## train a support vector machine
filter <- ksvm(type~.,data=spamtrain,kernel="rbfdot",
kpar=list(sigma=0.05),C=5,cross=3)
filter
## predict mail type on the test set
mailtype <- predict(filter,spamtest[,-58])
## Check results
table(mailtype,spamtest[,58])
## Another example with the famous iris data
data(iris)
## Create a kernel function using the build in rbfdot function
rbf <- rbfdot(sigma=0.1)
rbf
## train a bound constraint support vector machine
irismodel <- ksvm(Species~.,data=iris,type="C-bsvc",
kernel=rbf,C=10,prob.model=TRUE)
irismodel
## get fitted values
fitted(irismodel)
## Test on the training set with probabilities as output
predict(irismodel, iris[,-5], type="probabilities")
## Demo of the plot function
x <- rbind(matrix(rnorm(120),,2),matrix(rnorm(120,mean=3),,2))
y <- matrix(c(rep(1,60),rep(-1,60)))
svp <- ksvm(x,y,type="C-svc")
plot(svp,data=x)
### Use kernelMatrix
K <- as.kernelMatrix(crossprod(t(x)))
svp2 <- ksvm(K, y, type="C-svc")
svp2
# test data
xtest <- rbind(matrix(rnorm(20),,2),matrix(rnorm(20,mean=3),,2))
Ktest <- as.kernelMatrix(crossprod(t(xtest),t(x[SVindex(svp2), ])))
predict(svp2, Ktest)
k <- function(x,y) {(sum(x*y) +1)*exp(-0.001*sum((x-y)^2))}
class(k) <- "kernel"
data(promotergene)
## train svm using custom kernel
gene <- ksvm(Class~.,data=promotergene[c(1:20, 80:100),],kernel=k,
C=5,cross=5)
gene
#### Use text with string kernels
data(reuters)
is(reuters)
tsv <- ksvm(reuters,rlabels,kernel="stringdot",
kpar=list(length=5),cross=3,C=10)
tsv
## regression
# create data
x <- seq(-20,20,0.1)
y <- sin(x)/x + rnorm(401,sd=0.03)
# train support vector machine
regm <- ksvm(x,y,epsilon=0.01,kpar=list(sigma=16),cross=3)
plot(x,y,type="l")
lines(x,predict(regm,x),col="red")
rm(list = ls())
library(gglasso)
## load bardet data set
data(bardet)
dim(bardet$x)    # 120 100
x=bardet$x
View(x[,1:10])
y=bardet$y
y01 <- ifelse(y >= mean(y), 1, 0)
y11 <- 2*y01-1
View(x)
## load bardet data set
data(bardet)
dim(bardet$x)    # 120 100
x=bardet$x
View(x[,1:10])
y=bardet$y
y01 <- ifelse(y >= mean(y), 1, 0)
y11 <- 2*y01-1
# define group index
group <- rep(1:20,each=5)    # 100个samples, 20组，每组5个sample
## loss = c("ls", "logit", "sqsvm", "hsvm", "wls"),
## pred.loss = c("misclass", "loss", "L1", "L2")
# 5-fold cross validation using group lasso
# penalized logisitic regression
cv <- cv.gglasso(x, y11, group=group, loss="hsvm",
pred.loss="misclass", lambda.factor=0.05, nfolds=5)
# make a CV plot
plot(cv)
# fit group lasso penalized least squares
# m1 <- gglasso(x, y, group=group, loss="ls")
m2 <- gglasso(x, y11, group=group, loss="sqsvm")
coef <- coef(m2,s=cv$lambda.1se)
plot(m2)
# 5-fold cross validation using group lasso
# penalized logisitic regression
cv <- cv.gglasso(x, y11, group=group, loss="sqsvm",
pred.loss="misclass", lambda.factor=0.05, nfolds=5)
# make a CV plot
plot(cv)
# fit group lasso penalized least squares
# m1 <- gglasso(x, y, group=group, loss="ls")
m2 <- gglasso(x, y11, group=group, loss="sqsvm")
coef <- coef(m2,s=cv$lambda.1se)
plot(m2)
m <- gglasso(x, y11, group=group, loss="sqsvm", lambda = cv$lambda.1se)
m$beta
predict(m2, type="class", newx=bardet$x[10,])
pred<-predict(m2, type="class", newx=bardet$x[10,])
pred
View(pred)
pred<-predict(m2, newx=bardet$x)
pred
View(pred)
predict(m1,type="link",newx=colon$x[1:5,])
predict(m2,type="link",newx=colon$x[1:5,])
predict(m2,type="link",newx=bardet$x[1:5,])
View(m2)
bardet$x
pred<-predict(m, newx=bardet$x)
pred
install.packages("pomp",repos="https://kingaa.github.io/")
library(pomp)
rm(list = ls())
install.packages("pomp",repos="https://kingaa.github.io/")
library(pomp)
rm(list = ls())
# options(digits = 7)
##
set.seed(123)
##
method <- 2
## 0-不排除对角线
noDIAG = 1
AUCALL <- c()
ResultAll <- c()
meanAUCAccAll <- c()
l <- 21
setwd("D:\\E\\博士\\R_程序\\Boolean/Data/DREAM/DREAM3 in silico challenge/Size100/Data without noise")
data = as.matrix(read.table(file = "InSilicoSize100-Ecoli1-nonoise-trajectories.tsv", header=T))
run <- dim(data)[1]/l
run
View(data[,1])
